{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb475342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-12-12 12:50:02,081] [INFO] Set up nlp object from config\n",
      "[2022-12-12 12:50:02,088] [INFO] Pipeline: ['transformer', 'ner']\n",
      "[2022-12-12 12:50:02,090] [INFO] Created vocabulary\n",
      "[2022-12-12 12:50:02,091] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[2022-12-12 12:50:19,748] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
      "  0       0          62.14     98.91    0.03    0.02    0.30    0.00\n",
      "  0      10         603.91    986.85    0.03    0.02    0.30    0.00\n",
      "  0      20         540.30    898.37    0.03    0.02    0.30    0.00\n",
      "  0      30         460.31    761.66    0.03    0.02    0.30    0.00\n",
      "  0      40         401.01    664.32    0.00    0.00    0.00    0.00\n",
      "  0      50          80.44    165.52    0.00    0.00    0.00    0.00\n",
      "  0      60          54.42    114.58    0.00    0.00    0.00    0.00\n",
      "  0      70          39.43     90.89    0.00    0.00    0.00    0.00\n",
      "  0      80          34.45     95.53    0.00    0.00    0.00    0.00\n",
      "  0      90          27.81     62.82    0.00    0.00    0.00    0.00\n",
      "  0     100          30.59     74.44    2.30    5.51    1.45    0.02\n",
      "  0     110          26.95     64.51    0.70    1.45    0.46    0.01\n",
      "  0     120          77.07     79.83    1.34    2.66    0.89    0.01\n",
      "  0     130         287.00     92.93    6.20    7.03    5.55    0.06\n",
      "  0     140         316.49    114.15    8.54    8.22    8.88    0.09\n",
      "  0     150          73.62     61.35    8.27    9.44    7.36    0.08\n",
      "  0     160          52.13     68.93   13.14   14.60   11.96    0.13\n",
      "  0     170         156.18    123.40   15.01   16.26   13.94    0.15\n",
      "  0     180          37.80     81.81   13.83   14.47   13.24    0.14\n",
      "  0     190         121.53     84.91    8.84    7.40   11.00    0.09\n",
      "  0     200          96.95     95.24   14.92   13.82   16.22    0.15\n",
      "  1     210         192.89     94.56   16.49   16.64   16.35    0.16\n",
      "  1     220         158.25     79.52   10.68    9.16   12.81    0.11\n",
      "  1     230          61.13     82.69   17.34   15.52   19.65    0.17\n",
      "  1     240         794.69    156.15   15.81   18.73   13.67    0.16\n",
      "  1     250          72.69     81.37   19.87   23.95   16.97    0.20\n",
      "  1     260          97.08     95.52   13.94   12.31   16.05    0.14\n",
      "  1     270         813.30    228.35   14.43   13.06   16.12    0.14\n",
      "  1     280         253.82    114.42   12.92   13.00   12.85    0.13\n",
      "  1     290          57.88     71.26   15.07   15.29   14.86    0.15\n",
      "  1     300          36.47     82.89   17.27   14.75   20.81    0.17\n",
      "  1     310          90.61     98.14   17.01   16.27   17.83    0.17\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train training/config2.cfg --output ./output --paths.train training/Combined_Data_Judgement_Preamble_spacy_format/train.spacy --paths.dev training/Combined_Data_Judgement_Preamble_spacy_format/dev.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f40f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
