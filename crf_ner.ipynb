{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b1f8a33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from utils import load_training_data, convert_biluo_scheme\n",
    "\n",
    "train_judgement_path = './NER_TRAIN/NER_TRAIN_JUDGEMENT.json'\n",
    "train_preamble_path = './NER_TRAIN/NER_TRAIN_PREAMBLE.json'\n",
    "\n",
    "dev_judgement_path = './NER_DEV/NER_DEV_JUDGEMENT.json'\n",
    "dev_preamble_path = './NER_DEV/NER_DEV_PREAMBLE.json'\n",
    "\n",
    "train_judgement_data = load_training_data(train_judgement_path, False)\n",
    "train_preamble_data = load_training_data(train_preamble_path, True)\n",
    "all_training_data = train_judgement_data + train_preamble_data\n",
    "shuffle(all_training_data)\n",
    "\n",
    "dev_judgement_data = load_training_data(dev_judgement_path, False)\n",
    "dev_preamble_data = load_training_data(dev_preamble_path, True)\n",
    "all_dev_data = dev_judgement_data + dev_preamble_data\n",
    "shuffle(all_dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c7685a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>PREAMBLE</th>\n",
       "      <th>ENTITIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arguably, MOHUN is a common and/or a household...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(10, 15, ORG)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n5.2 CW3 Mr Vijay Mishra , Deputy Manager, H...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(13, 25, WITNESS), (44, 60, ORG), (62, 64, GP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was alleged that the meeting was held irreg...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(110, 131, OTHER_PERSON), (171, 193, OTHER_PE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Will was also witnessed by another attesti...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(57, 70, WITNESS), (106, 118, WITNESS), (160,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this connection it would be relevant to ref...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(52, 67, PRECEDENT), (101, 114, COURT), (152,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  PREAMBLE  \\\n",
       "0  Arguably, MOHUN is a common and/or a household...     False   \n",
       "1   \\n5.2 CW3 Mr Vijay Mishra , Deputy Manager, H...     False   \n",
       "2  It was alleged that the meeting was held irreg...     False   \n",
       "3  The Will was also witnessed by another attesti...     False   \n",
       "4  In this connection it would be relevant to ref...     False   \n",
       "\n",
       "                                            ENTITIES  \n",
       "0                                    [(10, 15, ORG)]  \n",
       "1  [(13, 25, WITNESS), (44, 60, ORG), (62, 64, GP...  \n",
       "2  [(110, 131, OTHER_PERSON), (171, 193, OTHER_PE...  \n",
       "3  [(57, 70, WITNESS), (106, 118, WITNESS), (160,...  \n",
       "4  [(52, 67, PRECEDENT), (101, 114, COURT), (152,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.DataFrame(all_training_data, columns = [\"TEXT\", \"PREAMBLE\", \"ENTITIES\"])\n",
    "training_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426f788f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>PREAMBLE</th>\n",
       "      <th>ENTITIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The amount of Rs.1,03,000/­, which was receive...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(51, 62, OTHER_PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High Court Of Judicature At Allahabad\\n \\n \\n\\...</td>\n",
       "      <td>True</td>\n",
       "      <td>[(0, 37, COURT), (315, 354, PETITIONER), (371,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the purposes of this sub-section, certific...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(98, 128, PROVISION), (166, 181, PROVISION), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Challenging the same, the State of Telangana f...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(26, 44, ORG), (51, 82, CASE_NUMBER), (90, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[see Koteshwar Vittal Kamath v, K. Rangappa &amp; ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(5, 63, PRECEDENT)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  PREAMBLE  \\\n",
       "0  The amount of Rs.1,03,000/­, which was receive...     False   \n",
       "1  High Court Of Judicature At Allahabad\\n \\n \\n\\...      True   \n",
       "2  For the purposes of this sub-section, certific...     False   \n",
       "3  Challenging the same, the State of Telangana f...     False   \n",
       "4  [see Koteshwar Vittal Kamath v, K. Rangappa & ...     False   \n",
       "\n",
       "                                            ENTITIES  \n",
       "0                           [(51, 62, OTHER_PERSON)]  \n",
       "1  [(0, 37, COURT), (315, 354, PETITIONER), (371,...  \n",
       "2  [(98, 128, PROVISION), (166, 181, PROVISION), ...  \n",
       "3  [(26, 44, ORG), (51, 82, CASE_NUMBER), (90, 11...  \n",
       "4                               [(5, 63, PRECEDENT)]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df = pd.DataFrame(all_dev_data, columns = [\"TEXT\", \"PREAMBLE\", \"ENTITIES\"])\n",
    "dev_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fde9d54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>PREAMBLE</th>\n",
       "      <th>ENTITIES</th>\n",
       "      <th>BILUO_LABELS</th>\n",
       "      <th>BIO_LABELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arguably, MOHUN is a common and/or a household...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(10, 15, ORG)]</td>\n",
       "      <td>[O, O, U-ORG, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n5.2 CW3 Mr Vijay Mishra , Deputy Manager, H...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(13, 25, WITNESS), (44, 60, ORG), (62, 64, GP...</td>\n",
       "      <td>[O, O, O, O, B-WITNESS, L-WITNESS, O, O, O, O,...</td>\n",
       "      <td>[O, O, O, O, B-WITNESS, I-WITNESS, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was alleged that the meeting was held irreg...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(110, 131, OTHER_PERSON), (171, 193, OTHER_PE...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Will was also witnessed by another attesti...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(57, 70, WITNESS), (106, 118, WITNESS), (160,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-WITNESS, L-WITNE...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-WITNESS, I-WITNE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this connection it would be relevant to ref...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(52, 67, PRECEDENT), (101, 114, COURT), (152,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRECEDENT, I-...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PRECEDENT, I-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  PREAMBLE  \\\n",
       "0  Arguably, MOHUN is a common and/or a household...     False   \n",
       "1   \\n5.2 CW3 Mr Vijay Mishra , Deputy Manager, H...     False   \n",
       "2  It was alleged that the meeting was held irreg...     False   \n",
       "3  The Will was also witnessed by another attesti...     False   \n",
       "4  In this connection it would be relevant to ref...     False   \n",
       "\n",
       "                                            ENTITIES  \\\n",
       "0                                    [(10, 15, ORG)]   \n",
       "1  [(13, 25, WITNESS), (44, 60, ORG), (62, 64, GP...   \n",
       "2  [(110, 131, OTHER_PERSON), (171, 193, OTHER_PE...   \n",
       "3  [(57, 70, WITNESS), (106, 118, WITNESS), (160,...   \n",
       "4  [(52, 67, PRECEDENT), (101, 114, COURT), (152,...   \n",
       "\n",
       "                                        BILUO_LABELS  \\\n",
       "0  [O, O, U-ORG, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "1  [O, O, O, O, B-WITNESS, L-WITNESS, O, O, O, O,...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, O, O, O, O, O, O, O, B-WITNESS, L-WITNE...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, B-PRECEDENT, I-...   \n",
       "\n",
       "                                          BIO_LABELS  \n",
       "0  [O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "1  [O, O, O, O, B-WITNESS, I-WITNESS, O, O, O, O,...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, B-WITNESS, I-WITNE...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, B-PRECEDENT, I-...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = English()\n",
    "biluo_labels, bio_labels = convert_biluo_scheme(all_training_data, nlp)\n",
    "training_df[\"BILUO_LABELS\"] = biluo_labels\n",
    "training_df[\"BIO_LABELS\"] = bio_labels\n",
    "training_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9a9985",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"High Court Of Judicature At Allahabad\n",
      " \n",
      " \n",
      "\n",
      "       ...\" with entities \"[(0, 37, 'COURT'), (315, 354, 'PETITIONER'), (371,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"W.P.No.9267 of 2017\n",
      "\n",
      "                             ...\" with entities \"[(63, 97, 'COURT'), (295, 306, 'JUDGE'), (426, 444...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"C/Lpa/1655/2019                             Judgme...\" with entities \"[(95, 129, 'COURT'), (466, 479, 'JUDGE'), (545, 56...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"1\n",
      "\n",
      "\n",
      "                                              ...\" with entities \"[(120, 142, 'COURT'), (269, 283, 'PETITIONER'), (4...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"Mr. Arun Bharadwaj, ld. CGSC, appearing for the Un...\" with entities \"[(4, 18, 'OTHER_PERSON'), (48, 62, 'ORG'), (111, 1...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"The respondent M/s. Ultratech Cement Ltd. (hereina...\" with entities \"[(20, 41, 'RESPONDENT'), (179, 191, 'OTHER_PERSON'...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"1\n",
      "\n",
      "                            Before The Madurai ...\" with entities \"[(42, 76, 'COURT'), (268, 280, 'JUDGE'), (543, 573...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"In The High Court Of Judicature At Madras\n",
      "\n",
      "       ...\" with entities \"[(7, 41, 'COURT'), (232, 244, 'JUDGE'), (342, 432,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"This will be clarified in the instant case by comp...\" with entities \"[(60, 127, 'PROVISION')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"Non­Reportable\n",
      "                                 In...\" with entities \"[(55, 77, 'COURT'), (218, 236, 'PETITIONER'), (339...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"\n",
      "    Commercial Complex, Raj Bhavan Road, Hyderaba...\" with entities \"[(42, 51, 'GPE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"High Court Of Judicature At Allahabad, Lucknow Ben...\" with entities \"[(0, 52, 'COURT'), (175, 184, 'PETITIONER'), (213,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"We may also point out that on an earlier occasion ...\" with entities \"[(92, 121, 'CASE_NUMBER'), (145, 173, 'PRECEDENT')...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"(Manohar Lal Sharma14; Committee for Protection of...\" with entities \"[(1, 19, 'OTHER_PERSON'), (23, 68, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"High Court Of Judicature At Allahabad\n",
      " \n",
      " \n",
      "\n",
      "Afr\n",
      " \n",
      "R...\" with entities \"[(0, 37, 'COURT'), (130, 168, 'PETITIONER'), (197,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"It is in that context that the observations made b...\" with entities \"[(78, 85, 'OTHER_PERSON'), (205, 329, 'PRECEDENT')...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"\n",
      "\n",
      "Digitally signed by:RAJENDER SINGH KARKI Signing...\" with entities \"[(22, 42, 'OTHER_PERSON'), (56, 66, 'DATE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"It is further urged that the aforesaid three decis...\" with entities \"[(113, 126, 'COURT'), (190, 209, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"There is no mechanism for Patna High Court REQ. CA...\" with entities \"[(26, 42, 'COURT'), (48, 68, 'CASE_NUMBER'), (72, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"The said judgment was reported in M. Venkateswara ...\" with entities \"[(32, 96, 'PRECEDENT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"\n",
      "\n",
      " (c) The aforesaid cheque was presented by the c...\" with entities \"[(93, 104, 'ORG'), (118, 127, 'GPE'), (226, 236, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"Honourable Dr. Justice B.Siva Sankara Rao         ...\" with entities \"[(23, 41, 'JUDGE'), (103, 125, 'PETITIONER'), (174...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"\n",
      " Likewise, In the power of attorney (exhibit P/11...\" with entities \"[(70, 84, 'OTHER_PERSON'), (98, 109, 'OTHER_PERSON...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"68 Marata(J) final.doc available in the Sate of Ma...\" with entities \"[(48, 59, 'GPE'), (160, 170, 'COURT'), (193, 228, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"In The High Court For The State Of Telangana\n",
      "     ...\" with entities \"[(7, 45, 'COURT'), (190, 201, 'JUDGE'), (330, 348,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"In The High Court Of Karnataka At Bengaluru\n",
      "\n",
      "    D...\" with entities \"[(7, 43, 'COURT'), (138, 159, 'JUDGE'), (291, 307,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"It is seen from the record that the arbitration pr...\" with entities \"[(88, 99, 'OTHER_PERSON'), (171, 180, 'GPE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>PREAMBLE</th>\n",
       "      <th>ENTITIES</th>\n",
       "      <th>BILUO_LABELS</th>\n",
       "      <th>BIO_LABELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The amount of Rs.1,03,000/­, which was receive...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(51, 62, OTHER_PERSON)]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, U-OTHER_PERSON, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-OTHER_PERSON, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High Court Of Judicature At Allahabad\\n \\n \\n\\...</td>\n",
       "      <td>True</td>\n",
       "      <td>[(0, 37, COURT), (315, 354, PETITIONER), (371,...</td>\n",
       "      <td>[B-COURT, I-COURT, I-COURT, I-COURT, I-COURT, ...</td>\n",
       "      <td>[B-COURT, I-COURT, I-COURT, I-COURT, I-COURT, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the purposes of this sub-section, certific...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(98, 128, PROVISION), (166, 181, PROVISION), ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Challenging the same, the State of Telangana f...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(26, 44, ORG), (51, 82, CASE_NUMBER), (90, 11...</td>\n",
       "      <td>[O, O, O, O, O, B-ORG, I-ORG, L-ORG, O, B-CASE...</td>\n",
       "      <td>[O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, B-CASE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[see Koteshwar Vittal Kamath v, K. Rangappa &amp; ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[(5, 63, PRECEDENT)]</td>\n",
       "      <td>[O, O, B-PRECEDENT, I-PRECEDENT, I-PRECEDENT, ...</td>\n",
       "      <td>[O, O, B-PRECEDENT, I-PRECEDENT, I-PRECEDENT, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  PREAMBLE  \\\n",
       "0  The amount of Rs.1,03,000/­, which was receive...     False   \n",
       "1  High Court Of Judicature At Allahabad\\n \\n \\n\\...      True   \n",
       "2  For the purposes of this sub-section, certific...     False   \n",
       "3  Challenging the same, the State of Telangana f...     False   \n",
       "4  [see Koteshwar Vittal Kamath v, K. Rangappa & ...     False   \n",
       "\n",
       "                                            ENTITIES  \\\n",
       "0                           [(51, 62, OTHER_PERSON)]   \n",
       "1  [(0, 37, COURT), (315, 354, PETITIONER), (371,...   \n",
       "2  [(98, 128, PROVISION), (166, 181, PROVISION), ...   \n",
       "3  [(26, 44, ORG), (51, 82, CASE_NUMBER), (90, 11...   \n",
       "4                               [(5, 63, PRECEDENT)]   \n",
       "\n",
       "                                        BILUO_LABELS  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, U-OTHER_PERSON, O,...   \n",
       "1  [B-COURT, I-COURT, I-COURT, I-COURT, I-COURT, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, O, O, O, B-ORG, I-ORG, L-ORG, O, B-CASE...   \n",
       "4  [O, O, B-PRECEDENT, I-PRECEDENT, I-PRECEDENT, ...   \n",
       "\n",
       "                                          BIO_LABELS  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-OTHER_PERSON, O,...  \n",
       "1  [B-COURT, I-COURT, I-COURT, I-COURT, I-COURT, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, B-CASE...  \n",
       "4  [O, O, B-PRECEDENT, I-PRECEDENT, I-PRECEDENT, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biluo_labels, bio_labels = convert_biluo_scheme(all_dev_data, nlp)\n",
    "dev_df[\"BILUO_LABELS\"] = biluo_labels\n",
    "dev_df[\"BIO_LABELS\"] = bio_labels\n",
    "dev_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1488ad86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import encode_label_ids\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "train_biluo_labels = training_df[\"BILUO_LABELS\"].values.tolist()\n",
    "train_biluo_labels = list(np.concatenate(biluo_labels).flat)\n",
    "\n",
    "labels2i, ids_to_label = encode_label_ids(train_biluo_labels)\n",
    "\n",
    "training_sents = []\n",
    "training_pos = []\n",
    "for data in all_training_data:\n",
    "    tokens = nlp(data[0])\n",
    "    pos = [token.pos_ for token in tokens]\n",
    "    tokens = [str(token) for token in tokens]\n",
    "    training_sents.append(tokens)\n",
    "    training_pos.append(pos)\n",
    "\n",
    "dev_sents = []\n",
    "dev_pos = []\n",
    "for data in all_dev_data:\n",
    "    tokens = nlp(data[0])\n",
    "    pos = [token.pos_ for token in tokens]\n",
    "    tokens = [str(token) for token in tokens]\n",
    "    dev_sents.append(tokens)\n",
    "    dev_pos.append(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bae4bbc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_observation_dict():\n",
    "    tokensList = []\n",
    "    for data in all_training_data:\n",
    "        tokens = nlp(data[0])\n",
    "        tokens = [str(token) for token in tokens]\n",
    "        tokensList = tokensList + tokens\n",
    "    words = list(set(tokensList))\n",
    "    words.sort()\n",
    "    observation_dict = {word: i for i, word in enumerate(words)}\n",
    "    return observation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00df3845",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id of the <unk> token: 45230\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "observation_dict = get_observation_dict()\n",
    "\n",
    "UNK_TOKEN = '<unk>'\n",
    "\n",
    "observation_dict[UNK_TOKEN] = len(observation_dict)\n",
    "print(\"id of the <unk> token:\", observation_dict[UNK_TOKEN])\n",
    "\n",
    "def encode(sentences: List[List[str]]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Using the observation_dict, convert the tokens to ids\n",
    "    unknown words take the id for UNK_TOKEN\n",
    "    \"\"\"\n",
    "    return [\n",
    "        [observation_dict[t] if t in observation_dict else observation_dict[UNK_TOKEN]\n",
    "            for t in sentence]\n",
    "        for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d071a47a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Anuj Bhavani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Anuj\n",
      "[nltk_data]     Bhavani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c66925d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def make_features(text: List[str], tags: List[str], is_preamble: bool) -> List[List[int]]:\n",
    "    \"\"\"Turn a text into a feature vector.\n",
    "\n",
    "    Args:\n",
    "        text (List[str]): List of tokens.\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: List of feature Lists.\n",
    "    \"\"\"\n",
    "    feature_lists = []\n",
    "    for i, token in enumerate(text):\n",
    "        feats = []\n",
    "        feats.append(f\"word={token}\")\n",
    "        feats.append(f\"pos={tags[i]}\")\n",
    "        if i == 0:\n",
    "            feats.append(f\"prev_word=<S>\");\n",
    "        else:\n",
    "            feats.append(f\"prev_word={text[i-1]}\")\n",
    "        if i == len(text) - 1:\n",
    "            feats.append(f\"next_word=<E>\")\n",
    "        else:\n",
    "            feats.append(f\"next_word={text[i+1]}\")\n",
    "        if is_preamble:\n",
    "            feats.append(f\"sentence_type=PREAMBLE\");\n",
    "        else:\n",
    "            feats.append(f\"sentence_type=JUDGEMENT\");\n",
    "        feature_lists.append(feats)\n",
    "    return feature_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d74a327c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def featurize(sents: List[List[str]], tags: List[List[str]], is_preamble_list: List[bool]) -> List[List[List[str]]]:\n",
    "    \"\"\"Turn the sentences into feature Lists.\n",
    "    \n",
    "    Eg.: For an input of 1 sentence:\n",
    "         [[['I','am','a','student','at','CU','Boulder']]]\n",
    "        Return list of features for every token for every sentence like:\n",
    "        [[\n",
    "         ['word=I',  'prev_word=<S>','pos=PRON',...],\n",
    "         ['word=an', 'prev_word=I'  , 'pos=VB' ,...],\n",
    "         [...]\n",
    "        ]]\n",
    "\n",
    "    Args:\n",
    "        sents (List[List[str]]): A List of sentences, which are Lists of tokens.\n",
    "\n",
    "    Returns:\n",
    "        List[List[List[str]]]: A List of sentences, which are Lists of feature Lists\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    for i in range(len(sents)):\n",
    "        feature = make_features(sents[i], tags[i], is_preamble_list[i])\n",
    "        feats.append(feature)\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca165b43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# File referenced from https://github.com/csci5832-f22/assignment_3\n",
    "from crf import *\n",
    "import random\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_features,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "    labels2i,\n",
    "    pad_feature_idx\n",
    "):\n",
    "    samples = list(zip(train_features, train_labels))\n",
    "    random.shuffle(samples)\n",
    "    batches = []\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        batches.append(samples[i:i+batch_size])\n",
    "    print(\"Training...\")\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for batch in tqdm(batches):\n",
    "            features, labels = zip(*batch)\n",
    "            features = pad_features(features, pad_feature_idx)\n",
    "            features = torch.stack(features)\n",
    "            labels = pad_labels(labels, labels2i[PAD_SYMBOL])\n",
    "            labels = torch.stack(labels)\n",
    "            mask = (labels != labels2i[PAD_SYMBOL])\n",
    "            optimizer.zero_grad()\n",
    "            loss = -model.forward(features, labels, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        dev_predictions = predict(model, dev_features)\n",
    "        dev_f1 = f1_score(dev_predictions, dev_labels, labels2i['O'])\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51c2b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features set!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10995/10995 [00:00<00:00, 13249.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135236 features\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06709a6266c6404ba8ed06e3cb0c3fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 30.037935635724732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuj Bhavani\\anaconda3\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorCompare.cpp:402.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 tensor([0.3165])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0f307c2c3c46718332671d33f0c4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 18.84659894330557\n",
      "Dev F1 tensor([0.3923])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c34a44ff5044d6fac82ddc3a9e69939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 15.04430908311245\n",
      "Dev F1 tensor([0.4258])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbdd6f699744db0aa4c5b93fea10e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 13.334273163445813\n",
      "Dev F1 tensor([0.4496])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f1d44889dc4207b38ea6af79d32bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 11.963907626695757\n",
      "Dev F1 tensor([0.4641])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47f3d419e2848a08b5d62bbf34ea35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss: 11.231360014094863\n",
      "Dev F1 tensor([0.4834])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afa15010e43401c947988e82143640c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss: 10.808272881346733\n",
      "Dev F1 tensor([0.4926])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab5f68eb9154e1c92842309c4f5cd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss: 10.478986611199934\n",
      "Dev F1 tensor([0.5009])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbdf4793ead49a7bca52924e1ecb040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss: 10.14004073032113\n",
      "Dev F1 tensor([0.5043])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadcfeb8de9d42f98e0159e8810394c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss: 9.573550282522689\n",
      "Dev F1 tensor([0.5094])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d6b2fa54a14cecb5d5de28aa0dd6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss: 9.816281018107263\n",
      "Dev F1 tensor([0.5182])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6692f95f453742269908c12aaeb7d13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, loss: 9.050171446661617\n",
      "Dev F1 tensor([0.5202])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b52b300f4943268fcd7051f00b1242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss: 8.817352151693127\n",
      "Dev F1 tensor([0.5233])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d778850b2ac4aabbcea01c03d9d23ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from crf import build_features_set\n",
    "from crf import make_features_dict\n",
    "from crf import encode_features, encode_labels\n",
    "from crf import NERTagger\n",
    "\n",
    "train_sents_is_preamble = training_df[\"PREAMBLE\"].values.tolist()\n",
    "dev_sents_is_preamble = dev_df[\"PREAMBLE\"].values.tolist()\n",
    "\n",
    "train_features = featurize(training_sents, training_pos, train_sents_is_preamble)\n",
    "dev_features = featurize(dev_sents, dev_pos, dev_sents_is_preamble)\n",
    "\n",
    "all_features = build_features_set(train_features)\n",
    "features_dict = make_features_dict(all_features)\n",
    "model = NERTagger(len(features_dict), len(labels2i))\n",
    "\n",
    "encoded_train_features = encode_features(train_features, features_dict)\n",
    "encoded_dev_features = encode_features(dev_features, features_dict)\n",
    "train_tag_sents = training_df[\"BIO_LABELS\"].values.tolist()\n",
    "encoded_train_labels = encode_labels(train_tag_sents, labels2i)\n",
    "dev_tag_sents = dev_df[\"BIO_LABELS\"].values.tolist()\n",
    "encoded_dev_labels = encode_labels(dev_tag_sents, labels2i)\n",
    "\n",
    "num_epochs = 45\n",
    "batch_size = 16\n",
    "LR=0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), LR)\n",
    "model = training_loop(\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    encoded_train_features,\n",
    "    encoded_train_labels,\n",
    "    encoded_dev_features,\n",
    "    encoded_dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "    labels2i,\n",
    "    features_dict[PAD_SYMBOL]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d562fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}